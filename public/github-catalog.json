{
  "user": "Ridit07",
  "fetched_at": "2025-08-31T15:57:59.156Z",
  "asset_version": "1756655879156",
  "repos": [
    {
      "id": "R_kgDOKTo9ww",
      "name": "SIH-ATITHI-ABHINANDAN-TRAVEL-APP",
      "full_name": "Ridit07/SIH-ATITHI-ABHINANDAN-TRAVEL-APP",
      "html_url": "https://github.com/Ridit07/SIH-ATITHI-ABHINANDAN-TRAVEL-APP",
      "homepage": "",
      "description": "Award-winning travel & tourism platform with AI chatbot, profile matching, real-time assistance, and sustainable community network.",
      "language": "Jupyter Notebook",
      "stargazers_count": 1,
      "owner": "Ridit07",
      "topics": [
        "ai",
        "chatbot",
        "ml",
        "smart-india-hackathon",
        "travel"
      ]
    },
    {
      "id": "R_kgDOMVkHyg",
      "name": "Medical-Chatbot-LLM",
      "full_name": "Ridit07/Medical-Chatbot-LLM",
      "html_url": "https://github.com/Ridit07/Medical-Chatbot-LLM",
      "homepage": "",
      "description": "AI-powered medical chatbot that analyzes text and medical images (like skin lesions or chest X-rays) to detect possible health conditions, provide explanations with reasoning, and deliver conversational, human-like responses for educational and research purposes.",
      "language": "Jupyter Notebook",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "llm",
        "medical-chatbot",
        "pytorch",
        "healthcare-ai-image-classification"
      ]
    },
    {
      "id": "R_kgDOPav0Cw",
      "name": "Ridit07",
      "full_name": "Ridit07/Ridit07",
      "html_url": "https://github.com/Ridit07/Ridit07",
      "homepage": "",
      "description": "",
      "language": "",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": []
    },
    {
      "id": "R_kgDOO3VOwQ",
      "name": "Portfolio-Ridit-Jain",
      "full_name": "Ridit07/Portfolio-Ridit-Jain",
      "html_url": "https://github.com/Ridit07/Portfolio-Ridit-Jain",
      "homepage": "https://portfolio-ridit-jain.vercel.app",
      "description": "Portfolio website for Ridit Jain",
      "language": "JavaScript",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "portfolio-website",
        "reactjs"
      ]
    },
    {
      "id": "R_kgDOPaqXYw",
      "name": "Cryptography-in-QMT",
      "full_name": "Ridit07/Cryptography-in-QMT",
      "html_url": "https://github.com/Ridit07/Cryptography-in-QMT",
      "homepage": "",
      "description": "Quantum cryptography demo implementing BB84, BBM92, and TF-QKD protocols for secure key exchange, combined with AES/RSA for text and image encryption. Includes a React chatbot frontend and a Flask/Firebase backend powered by Qiskit simulations.",
      "language": "Jupyter Notebook",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "bb84",
        "bbm92",
        "flask",
        "qiskit",
        "qkd",
        "quantum-cryptography"
      ]
    },
    {
      "id": "R_kgDOPaoRMQ",
      "name": "Combining-ML-and-DL-Approaches-to-Enhance-Antimicrobial-Peptide-Discovery-and-Effectiveness",
      "full_name": "Ridit07/Combining-ML-and-DL-Approaches-to-Enhance-Antimicrobial-Peptide-Discovery-and-Effectiveness",
      "html_url": "https://github.com/Ridit07/Combining-ML-and-DL-Approaches-to-Enhance-Antimicrobial-Peptide-Discovery-and-Effectiveness",
      "homepage": "",
      "description": "Hybrid ML + DL approach for antimicrobial peptide discovery, combining sequence-based models with structural image analysis and explainable AI (SHAP, LIME) to identify key properties driving predictions.",
      "language": "Jupyter Notebook",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "cnn",
        "deep-learning",
        "explainable-ai",
        "lime",
        "machine-learning",
        "random-forest",
        "shap"
      ]
    },
    {
      "id": "R_kgDOJeguXw",
      "name": "IPL-Prediction-App",
      "full_name": "Ridit07/IPL-Prediction-App",
      "html_url": "https://github.com/Ridit07/IPL-Prediction-App",
      "homepage": "",
      "description": "IPLitics is a student-built Flutter + Flask application that brings together live IPL match data, player and team statistics, and basic machine learning–based predictions. Designed for cricket fans, it offers a clean UI, quick insights, and a simple analytics pipeline for batting and bowling performance.",
      "language": "Dart",
      "stargazers_count": 1,
      "owner": "Ridit07",
      "topics": [
        "flask",
        "flutter",
        "machine-learning",
        "python"
      ]
    },
    {
      "id": "R_kgDOKv6Z-g",
      "name": "Lane-Detection-Using-Deep-Learning",
      "full_name": "Ridit07/Lane-Detection-Using-Deep-Learning",
      "html_url": "https://github.com/Ridit07/Lane-Detection-Using-Deep-Learning",
      "homepage": "",
      "description": "A deep learning-based lane detection system using CNNs for robust, real-time identification of road lane markings, aimed at enhancing Advanced Driver Assistance Systems (ADAS) with high accuracy and reliability.",
      "language": "Jupyter Notebook",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "cnn",
        "deep-learning",
        "lane-detection",
        "opencv",
        "tensorflow"
      ]
    },
    {
      "id": "R_kgDOK1Ht9w",
      "name": "Image-based-Emotion-Age-Gender-Recognition-And-Song-Recommendation-System",
      "full_name": "Ridit07/Image-based-Emotion-Age-Gender-Recognition-And-Song-Recommendation-System",
      "html_url": "https://github.com/Ridit07/Image-based-Emotion-Age-Gender-Recognition-And-Song-Recommendation-System",
      "homepage": "",
      "description": "An AI-powered facial analysis system that detects a user’s emotion, age, and gender from a webcam feed, then recommends a personalized music playlist. Built using computer vision and machine learning, it combines emotion recognition, demographic prediction, and context-aware music recommendation for an engaging, real-time experience.",
      "language": "Jupyter Notebook",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "age-prediction",
        "computer-vision",
        "emotion-detection",
        "gender-prediction",
        "music-recommendation",
        "opencv",
        "python"
      ]
    },
    {
      "id": "R_kgDOMV5k1g",
      "name": "Research-ChatGPT-can-change-the-world",
      "full_name": "Ridit07/Research-ChatGPT-can-change-the-world",
      "html_url": "https://github.com/Ridit07/Research-ChatGPT-can-change-the-world",
      "homepage": "",
      "description": "Research study on the transformative potential of ChatGPT and generative AI, exploring applications, economic impact, and ethical considerations across industries.",
      "language": "",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "ai",
        "chatgpt"
      ]
    },
    {
      "id": "R_kgDOMV5zhg",
      "name": "Universal-Turing-Machine-Simulator",
      "full_name": "Ridit07/Universal-Turing-Machine-Simulator",
      "html_url": "https://github.com/Ridit07/Universal-Turing-Machine-Simulator",
      "homepage": "",
      "description": "This project simulates a Universal Turing Machine (UTM) that can take another Turing Machine (TM) and an input string w, and mimic the behavior of the TM. The UTM will accept or reject the string w based on the behavior of the TM.",
      "language": "Python",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "python",
        "turing-machine-simulator"
      ]
    },
    {
      "id": "R_kgDOMWtZWA",
      "name": "HCL-Internship-Demo-Recruitment-Invoice-Tool",
      "full_name": "Ridit07/HCL-Internship-Demo-Recruitment-Invoice-Tool",
      "html_url": "https://github.com/Ridit07/HCL-Internship-Demo-Recruitment-Invoice-Tool",
      "homepage": "",
      "description": "AI-assisted recruitment and invoicing tool built during HCL internship, streamlining vendor claims, verification, rate-card generation, and invoice preparation with role-based workflows.",
      "language": "Dart",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "flask",
        "flutter",
        "mysql",
        "python"
      ]
    },
    {
      "id": "R_kgDOMWub6Q",
      "name": "Selective-Mutism-Hand-Gesture-To-Text",
      "full_name": "Ridit07/Selective-Mutism-Hand-Gesture-To-Text",
      "html_url": "https://github.com/Ridit07/Selective-Mutism-Hand-Gesture-To-Text",
      "homepage": "",
      "description": "Real-time hand gesture recognition system for selective mutism, converting signs into text using computer vision and a Random Forest model, enabling hands-free communication.",
      "language": "Python",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "assistive-technology",
        "computer-vision",
        "gesture-recognition",
        "opencv",
        "python",
        "random-forest"
      ]
    },
    {
      "id": "R_kgDOMVkSiA",
      "name": "Nurturing-Positivity-Enhancing-News-Summarization-through-Reinforcement-Learning-LLM",
      "full_name": "Ridit07/Nurturing-Positivity-Enhancing-News-Summarization-through-Reinforcement-Learning-LLM",
      "html_url": "https://github.com/Ridit07/Nurturing-Positivity-Enhancing-News-Summarization-through-Reinforcement-Learning-LLM",
      "homepage": "",
      "description": "A novel approach to news summarization that promotes positive and constructive narratives by integrating sentiment and toxicity control into the summarisation process.",
      "language": "Jupyter Notebook",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "llm",
        "reinforcement-learning",
        "text-summarization",
        "toxicity-detection",
        "positive-content-generation"
      ]
    },
    {
      "id": "R_kgDOJUQCkQ",
      "name": "E-COMMERCE-PURCHASE-PREDICTION-ML",
      "full_name": "Ridit07/E-COMMERCE-PURCHASE-PREDICTION-ML",
      "html_url": "https://github.com/Ridit07/E-COMMERCE-PURCHASE-PREDICTION-ML",
      "homepage": "",
      "description": "Predict whether a customer will make a purchase on an e-commerce website using Machine Learning models, with 89% accuracy achieved via Random Forest.",
      "language": "Jupyter Notebook",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "machine-learning",
        "purchase-prediction",
        "python",
        "streamlit"
      ]
    },
    {
      "id": "R_kgDOMWRyhw",
      "name": "Interview-Pro",
      "full_name": "Ridit07/Interview-Pro",
      "html_url": "https://github.com/Ridit07/Interview-Pro",
      "homepage": "",
      "description": "Helps streamline the interview process with cheat detection, insight analysis, and structured evaluation reports.",
      "language": "Python",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": [
        "deep-learning",
        "flask",
        "mysql",
        "nlp",
        "python",
        "react",
        "webrtc"
      ]
    },
    {
      "id": "R_kgDOJFXIOA",
      "name": "Web-Browser",
      "full_name": "Ridit07/Web-Browser",
      "html_url": "https://github.com/Ridit07/Web-Browser",
      "homepage": "",
      "description": "",
      "language": "Python",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": []
    },
    {
      "id": "R_kgDOMVj33A",
      "name": "NLP-Powered-Legal-Document-Generation-System",
      "full_name": "Ridit07/NLP-Powered-Legal-Document-Generation-System",
      "html_url": "https://github.com/Ridit07/NLP-Powered-Legal-Document-Generation-System",
      "homepage": "",
      "description": "",
      "language": "Python",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": []
    },
    {
      "id": "R_kgDOLhVlGw",
      "name": "Classifying-Sentiment-of-Restaurant-Reviews-NLP",
      "full_name": "Ridit07/Classifying-Sentiment-of-Restaurant-Reviews-NLP",
      "html_url": "https://github.com/Ridit07/Classifying-Sentiment-of-Restaurant-Reviews-NLP",
      "homepage": "",
      "description": "",
      "language": "Jupyter Notebook",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": []
    },
    {
      "id": "R_kgDOIi9WYw",
      "name": "infinity-graphics-node",
      "full_name": "Ridit07/infinity-graphics-node",
      "html_url": "https://github.com/Ridit07/infinity-graphics-node",
      "homepage": "",
      "description": "",
      "language": "CSS",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": []
    },
    {
      "id": "R_kgDOIi87Nw",
      "name": "ridit07.github.io",
      "full_name": "Ridit07/ridit07.github.io",
      "html_url": "https://github.com/Ridit07/ridit07.github.io",
      "homepage": "",
      "description": "",
      "language": "HTML",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": []
    },
    {
      "id": "R_kgDOIgpRAA",
      "name": "Library-Management-App",
      "full_name": "Ridit07/Library-Management-App",
      "html_url": "https://github.com/Ridit07/Library-Management-App",
      "homepage": "",
      "description": "",
      "language": "Java",
      "stargazers_count": 0,
      "owner": "Ridit07",
      "topics": []
    }
  ],
  "pinned": [
    "ridit07/medical-chatbot-llm",
    "ridit07/interview-pro",
    "ridit07/lane-detection-using-deep-learning",
    "ridit07/sih-atithi-abhinandan-travel-app",
    "ridit07/ridit07.github.io",
    "ridit07/selective-mutism-hand-gesture-to-text"
  ],
  "readmes": {
    "ridit07/medical-chatbot-llm": "# 🩺 Medical Chatbot LLM\n\nAn AI-powered medical assistant capable of analyzing medical images and answering health-related queries.  \nThe chatbot is built on **Large Language Models (LLMs)** with integration of image understanding to identify possible medical conditions based on uploaded images.  \nIt provides **explanations with reasoning**, supports **multi-modal inputs** (text + images), and can detect potential issues like skin cancer or chest anomalies.\n\n---\n\n## 📌 Features\n\n- 🧠 **Medical Q&A** – Ask any medical question and get contextually relevant, evidence-based responses.\n- 🩻 **Image Analysis** – Upload medical images (X-rays, skin lesion photos, etc.) for AI-powered analysis.\n- 🔍 **Condition Detection** – Identifies possible symptoms or abnormalities with explanations.\n- 💬 **Conversational Interface** – Natural, human-like interaction for non-technical users.\n- 📊 **Explainable Results** – Includes reasoning and possible causes for predictions.\n\n---\n\n## 📂 Project Structure\n\nMedical-Chatbot-LLM/\n- ├── app.py # Main Streamlit application\n- ├── model/ # Trained model files\n- ├── utils/ # Helper functions for image/text processing\n- ├── Demo Images/ # Example input images for testing\n- ├── requirements.txt # Python dependencies\n- └── README.md # Project documentation\n\n\n---\n\n## 🚀 How It Works\n\n1. **Upload an image** (X-ray, skin lesion, etc.) or type a medical query.\n2. The **LLM model** processes the text and/or image.\n3. If an image is provided, the vision module extracts features and detects possible abnormalities.\n4. The chatbot generates a **diagnosis suggestion with reasoning**.\n5. The final output is displayed in an **interactive chat interface**.\n\n---\n\n## 🖼 Demo\n\n**Skin Lesion Detection**  \n<img src=\"Demo Images/Screenshot 2024-05-14 at 3.28.16 AM.png\" width=\"500\"/>\n\n**Chest X-ray Analysis**  \n<img src=\"Demo Images/Screenshot 2024-05-14 at 3.55.07 AM.png\" width=\"500\"/>\n\n**Multiple Image Checks**  \n<img src=\"Demo Images/Screenshot 2024-05-14 at 3.42.05 AM.png\" width=\"500\"/>\n\n---\n\n## 🛠 Tech Stack\n\n- **Python**\n- **Streamlit** – Web app interface\n- **OpenAI GPT / LLaVA / BLIP** – LLM + image understanding\n- **PyTorch** – Model training & inference\n- **Pillow / OpenCV** – Image preprocessing\n\n---\n\n## 📦 Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Ridit07/Medical-Chatbot-LLM.git\ncd Medical-Chatbot-LLM\n\n# Install dependencies\npip install -r requirements.txt\n\n# Run the app\nstreamlit run app.py\n```\n\n\n",
    "ridit07/interview-pro": "# RecruitAura\n\nAI-assisted technical interviews: real-time coding + voice transcription + fair, structured evaluation — all in one place.\n\n## Why this exists\n\nTechnical hiring is slow, expensive, and often bottlenecked by engineers’ time. RecruitAura automates the repetitive parts (scheduling, coding checks, transcripts, structured scoring) so teams can focus on decisions, not logistics.\n\n## What it does\n\n- **Live interview room** with video, chat, and a shared coding pad (compiles code via API)\n- **Speech-to-text** transcription during interviews (powered by Whisper)\n- **Insight extraction** from answers: keywords, entities, sentiment, and topic hints to aid the interviewer\n- **Signals for fairness & integrity** (e.g., toxicity/bias checks; optional non-verbal/cheat cues)\n- **ATS-style matching** between JD and resume using embeddings and TF-IDF\n- **Auto-summary** of long docs/answers for quick reviews\n- **Post-interview report** with rubric-based scoring and notes\n\n\n## Stack\n\n- **Frontend:** React.js (SPA)\n- **Backend:** Python (Flask)\n- **Database:** MySQL\n- **Real-time:** WebRTC for video; Firebase (Firestore/Storage) for room metadata, chat, and code pad sync\n- **ML/NLP:** PyTorch, Transformers; Whisper for ASR; BART for summarization; spaCy for NER; Sentence-BERT for JD↔Resume matching; YOLO for attire (optional)\n- **Code execution:** RapidAPI Code Compiler\n\n## Data model\n\n- `Candidate`, `Organisation`, `Interviewer`, `Interviews`, `Status`, `Rubrics`\n- Foreign key links between who, what, when, and the evaluation rubric per session\n\n## Suggested project layout\n\n/app\n/frontend # React app\n/backend # Flask API\n/docs\n\n\n## Getting started (local dev)\n\n### Prerequisites\n- Node 18+\n- Python 3.11+\n- MySQL 8+\n- Accounts/keys: Firebase (Firestore+Storage), RapidAPI compiler, OpenAI Whisper (or your ASR proxy)\n\n### Backend – Flask\n```bash\ncd app/backend\npython -m venv .venv && source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\npip install -r requirements.txt\n# set env (see below), then:\nflask db upgrade\nflask run\n```\n\n### Frontend – React\n```bash\n\ncd app/frontend\nnpm install\nnpm run dev\n```\n\n## How the interview flow works\n\n1. **Org** creates a role + rubric and adds candidates  \n2. **Org** schedules a slot with an interviewer  \n3. **Candidate** joins the room; code pad + mic start  \n4. **Backend** streams ASR → NLP insights; compiler runs code; room chat and edits sync via Firebase  \n5. **Interviewer** submits the rubric; a **report** is generated and stored  \n\n---\n\n## Models & signals\n\n- Summarization (BART)  \n- Emotion detection  \n- Lip-sync detection  \n- Dual-face detection  \n- Toxicity detection  \n- Bias detection  \n- Attire detection (experimental)  \n- JD↔Resume similarity via Sentence-BERT + TF-IDF  \n\n---\n\n## Roadmap\n\n- Improved bias auditing & explainability  \n- Interviewer coaching prompts (LLM-assisted)  \n- Multi-tenant org admin & SSO  \n- Exportable report templates  \n\n---\n\n## Contributing\n\nPRs welcome — especially for:\n- Improving evaluation rubrics and scoring UX  \n- Expanding test data & reproducible model evaluation  \n- Hardening WebRTC flows and TURN fallback  \n\nWhen opening an issue, include:\n1. Steps to reproduce  \n2. Expected vs actual result  \n3. Logs or screenshots if relevant  \n\n",
    "ridit07/lane-detection-using-deep-learning": "# 🛣️ Lane Detection Using Deep Learning\n\n## 📌 Overview\nThis project presents a **deep learning-based lane detection system** designed to accurately identify lane markings in road images and videos.  \nThe primary aim is to assist **Advanced Driver Assistance Systems (ADAS)** by providing robust lane detection in various driving conditions, enhancing road safety and driver awareness.\n\n## 🖼 Demo Results\n| Detected Lane Example 1 | Detected Lane Example 2 |\n|-------------------------|-------------------------|\n| ![Lane Detection Result 1](demo_image/image1.png) | ![Lane Detection Result 2](demo_image/image2.png) |\n\n## ⚙ How It Works\n1. **Data Acquisition** – Lane detection datasets with annotated lane markings were used.\n2. **Preprocessing** –  \n   - Resizing frames  \n   - Normalization  \n   - Noise reduction and edge enhancement  \n3. **Deep Learning Model** –  \n   - CNN-based semantic segmentation  \n   - Trained on annotated lane images to generate binary lane masks  \n4. **Post-processing** –  \n   - Lane contour extraction  \n   - Overlay of detected lanes on the original frame  \n5. **Output** – Continuous real-time lane marking visualization.\n\n## 🛠 Tech Stack\n- **Python** – Programming language\n- **OpenCV** – Image and video processing\n- **TensorFlow / Keras** – Deep learning framework\n- **NumPy / Pandas** – Data manipulation\n- **Matplotlib** – Visualization\n",
    "ridit07/sih-atithi-abhinandan-travel-app": "# 🏆 Travel & Tourism Ecosystem Platform — SIH 2023 Winner (Internal College)\n\n> **First Prize** in Internal College Round of Smart India Hackathon (SIH) 2023  \n> Team: **Illuminati** | Theme: **Travel & Tourism** | Problem Statement Code: **1486**\n\n---\n\n## 📌 Overview\n\nThe **Travel & Tourism Ecosystem Platform** is designed to revolutionize the tourism industry by combining **authenticity, real-time assistance, personalization, community engagement, and sustainability** — all in one ecosystem.\n\nUnlike existing portals that only focus on bookings, our platform offers **layered authenticity, real assistance, event planning, sustainable products/services, and a strong community network**.\n\n---\n\n## 🎯 Key Features\n\n### **1. MDM — Master Data Management**\n- Physical review & verification of tourism data.\n- Feedback, ratings, and follow-ups.\n- Market research & offers generation.\n- Yearly personalized event calendar (**CalendarConnect**).\n\n### **2. MIHU — \"May I Help You\" Chatbot**\n- Speech recognition support.\n- Real-time integration with Google APIs.\n- Nearby assistance (medical, restaurants, attractions).\n- **Panic Button** for Quick Response Team (QRT) — medical, weather, crime alerts.\n\n### **3. PME — Profile Matcher Engine**\n- AI/ML-based traveler profile analysis.\n- Personalized travel plans, recommendations, and forecasts.\n- Helps in planning, offers, and follow-ups.\n\n### **4. Hands Meet Club**\n- Local guides, homestays, F&B services, and cultural ambassadors.\n- Promotes **\"Atithi Devo Bhava\"** hospitality.\n- Sustainable tourism network.\n\n---\n\n## 🛠 Technology Stack\n\n- **Frontend:** HTML, CSS, JavaScript\n- **Backend:** Node.js / Express.js\n- **AI/ML:** Python (scikit-learn, TensorFlow), NLP for Chatbot\n- **Database:** MySQL / MongoDB\n- **Blockchain:** Secure transactions & transparent supply chain\n- **APIs:** Google APIs for maps, location, weather\n- **Security:** SSL certification, penetration & vulnerability testing, ERNET domain\n\n---\n\n## 📂 Project Modules\n\n1. **Authenticity Verification** (MDM)  \n2. **Real-time Assistance** (MIHU)  \n3. **Personalized Planning & Recommendations** (PME)  \n4. **Local Community Network** (Hands Meet Club)  \n5. **Event Calendar & Sustainable Options**  \n6. **Emergency Services & Panic Alerts**  \n7. **Community Forum Integration** (Reddit API)\n\n---\n\n## 📊 Expected Outcomes\n\n- Increased **trust & authenticity** in tourism information.\n- Real-time **assistance & safety** for travelers.\n- **Personalized experiences** based on AI/ML.\n- Promotion of **local culture & economy**.\n- Sustainable tourism ecosystem.\n\n---\n\n## 💡 Use Cases\n\n- Verified hotel and service listings.\n- Panic button for emergencies.\n- Personalized itineraries based on profile match.\n- Follow-ups & customer engagement.\n- Blockchain-based booking & payment transparency.\n\n---\n\n## 🚀 Roadmap\n\n- Deploy multi-language chatbot support.\n- Expand **Hands Meet Club** nationwide.\n- Integrate insurance partnerships (e.g., Acko).\n- Add AR/VR tourism experiences.\n\n---\n\n## 🏆 Achievements\n\n- **First Prize Winner** — Internal Round, **Smart India Hackathon 2023**\n- Recognized for **innovation, feasibility, and societal impact**.\n\n",
    "ridit07/ridit07.github.io": "",
    "ridit07/selective-mutism-hand-gesture-to-text": "# ✋ Selective Mutism — Hand Gesture ➜ Text\n\nAssistive, real-time **hand-gesture-to-text** system aimed at helping people with **selective mutism** (and anyone who prefers hands over voice) communicate using a webcam. The app detects a single hand, recognizes the sign, and builds words/sentences on screen.\n\n<img src=\"Demo_Image.png\" alt=\"Demo\" width=\"640\"/>\n\n---\n\n## Why this project?\n\nPeople who can’t speak in certain social situations often rely on gestures or writing. This tool turns **hand signs into text** instantly so conversations can flow in classrooms, workplaces, clinics, or day-to-day life.\n\n---\n\n## What it does\n\n- **Live hand tracking** via webcam  \n- **Gesture recognition** with a lightweight ML classifier (Random Forest)  \n- Uses **~42 features** from one hand (2D landmark pairs)  \n- **Word builder**: append predicted letters/words to an on-screen text area  \n- **Low-latency**: runs locally on CPU; no internet required\n\n---\n\n## Tech Stack\n\n- **Python**\n- **OpenCV** – camera frames & drawing\n- **MediaPipe** (or similar) – hand landmarks\n- **scikit-learn** – Random Forest classifier\n- **NumPy / Pandas** – feature processing\n\n> Model idea: extract 21 landmark points → normalize → build a 42-feature vector (x,y) → predict letter/word.\n\n---\n\n## Getting Started\n\n### 1) Clone\n```bash\ngit clone https://github.com/Ridit07/Selective-Mutism-Hand-Gesture-To-Text.git\ncd Selective-Mutism-Hand-Gesture-To-Text\n```\n\n### 2) Install deps\n```bash\n# create & activate a venv (recommended)\npython -m venv .venv\n# Windows\n.venv\\Scripts\\activate\n# macOS/Linux\nsource .venv/bin/activate\n\npip install -r requirements.txt\n\n```\n\n#If you don’t have a requirements.txt, install the essentials:\n\n```bash\npip install opencv-python mediapipe scikit-learn numpy pandas\n```\n\n### 3) Run\n```bash\npython app.py\n```\n\n---\n\n## ▶️ Usage\n\n1. **Allow webcam access** when prompted.  \n2. **Hold your hand inside the guide box** and show a supported sign.  \n3. Watch predictions appear in real time.  \n4. Press **Space** or **Enter** (or click the on-screen button) to add the prediction to the text area.  \n\n> 💡 If your entry file is named differently, run it accordingly:  \n> ```bash\n> python main.py\n> ```\n\n---\n\n## ⚙️ How It Works\n\n1. **Capture** – Read webcam frames using OpenCV.  \n2. **Landmarks** – Detect a single hand and extract **21 keypoints**.  \n3. **Features** – Normalize coordinates (scale/translate) into a **42-dimensional vector**.  \n4. **Predict** – Random Forest classifier maps features to a letter/word.  \n5. **Compose** – Append results into an editable text area for live communication.\n\n---\n\n## 🏋️‍♂️ Train Your Own Model (Optional)\n\n1. **Record landmark samples** for each class (A–Z / words).  \n2. **Build a CSV** of features and labels.  \n3. Train with:\n\n```python\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=300, max_depth=None, random_state=42)\nclf.fit(X_train, y_train)\n\n# Save model\nimport joblib\njoblib.dump(clf, \"models/rf_gesture.pkl\")\n```\n\n4. Replace the file models/rf_gesture.pkl in the app.\n\n",
    "ridit07/ridit07": "<h1 align=\"center\">Hey there 👋, I'm Ridit Jain</h1>\n<h3 align=\"center\">💡 Turning Ideas into Scalable Code | AI, Backend & Cloud Enthusiast</h3>\n\n---\n\n### 🚀 About Me\n- 🖥️ **Software Engineer** with experience in **Backend Development, AI/ML, and Cloud Deployments**.\n- 🔍 Passionate about **building AI-powered applications** and **optimizing backend systems**.\n- ⚡ Skilled in **Python, Java, JavaScript, Go, C++**, and **System Design**.\n- ☁️ Hands-on with **Azure, AWS, Docker**.\n- 🧠 Currently deep-diving into **LLM Fine-tuning** & **Scalable AI service deployments**.\n- 📈 Focused on **performance optimization**, **real-time systems**, and **developer productivity tools**.\n\n---\n\n### 🛠️ Tech Stack\n#### **Languages**\n![Python](https://img.shields.io/badge/Python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)\n![Java](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white)\n![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)\n![Go](https://img.shields.io/badge/Go-00ADD8?style=for-the-badge&logo=go&logoColor=white)\n![C++](https://img.shields.io/badge/C++-00599C?style=for-the-badge&logo=cplusplus&logoColor=white)\n\n#### **Backend & AI**\n![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)\n![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)\n![Spring Boot](https://img.shields.io/badge/Spring_Boot-6DB33F?style=for-the-badge&logo=springboot&logoColor=white)\n![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)\n![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)\n![gRPC](https://img.shields.io/badge/gRPC-512BD4?style=for-the-badge&logo=grpc&logoColor=white)\n\n#### **Databases**\n![MySQL](https://img.shields.io/badge/MySQL-005C84?style=for-the-badge&logo=mysql&logoColor=white)\n![Redis](https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=redis&logoColor=white)\n![DynamoDB](https://img.shields.io/badge/DynamoDB-4053D6?style=for-the-badge&logo=amazondynamodb&logoColor=white)\n\n\n#### **Cloud & DevOps**\n![Azure](https://img.shields.io/badge/Microsoft_Azure-0089D6?style=for-the-badge&logo=microsoft-azure&logoColor=white)\n![AWS](https://img.shields.io/badge/AWS-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)\n![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)\n\n#### **Tools & Platforms**\n![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)\n![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)\n![VS Code](https://img.shields.io/badge/VS_Code-0078d7?style=for-the-badge&logo=visual-studio-code&logoColor=white)\n![IntelliJ IDEA](https://img.shields.io/badge/IntelliJ_IDEA-000000?style=for-the-badge&logo=intellij-idea&logoColor=white)\n![Android Studio](https://img.shields.io/badge/Android_Studio-3DDC84?style=for-the-badge&logo=android-studio&logoColor=white)\n![Datadog](https://img.shields.io/badge/Datadog-632CA6?style=for-the-badge&logo=datadog&logoColor=white)\n![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)\n![Postman](https://img.shields.io/badge/Postman-FF6C37?style=for-the-badge&logo=postman&logoColor=white)\n![Redash](https://img.shields.io/badge/Redash-FF6363?style=for-the-badge&logo=redash&logoColor=white)\n![Log Store](https://img.shields.io/badge/Log%20Store-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)\n\n\n---\n\n### 📌 Featured Projects\n#### 🔹 [InterviewPro](https://github.com/Ridit07/Interview-Pro)\nAI-powered interview platform with live codepad, cheat detection (lip-sync, dual-face, bias, attire), real-time ASR & NLP insights, and structured evaluation reports.\n\n#### 🔹 [Selective Mutism — Hand Gesture to Text](https://github.com/Ridit07/Selective-Mutism-Hand-Gesture-To-Text)\nAssistive tech solution converting hand gestures into real-time text for individuals with selective mutism.\n\n#### 🔹 [HCL Recruitment Invoice Tool](https://github.com/Ridit07/HCL-Internship-Demo-Recruitment-Invoice-Tool)\nAutomated recruitment invoice verification & claim management system with AI-powered rate card validation.\n\n#### 🔹 [IPL Performance Prediction](https://github.com/Ridit07/IPL-Prediction-App)\nPredicts IPL **player performance metrics** using historical data, not just match outcomes.\n\n---\n\n### 📊 GitHub Stats\n<p align=\"center\">\n  <img src=\"https://github-readme-stats.vercel.app/api?username=Ridit07&show_icons=true&theme=radical\" alt=\"Ridit Jain's GitHub stats\" height=\"165\"/>\n  <img src=\"https://github-readme-stats.vercel.app/api/top-langs/?username=Ridit07&layout=compact&theme=radical\" height=\"165\"/>\n</p>\n\n---\n\n### 🏆 Competitive Programming\n[![LeetCode](https://img.shields.io/badge/LeetCode-FFA116?style=for-the-badge&logo=leetcode&logoColor=white)](https://leetcode.com/u/ridit_jain19/)\n\n\n### 🤝 Connect with Me\n[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/ridit-jain-479230214/)\n[![Gmail](https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:riditjain1@gmail.com)\n[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Ridit07)\n\n---\n\n> 💬 *\"Code is the closest thing we have to superpowers — I just keep upgrading mine.\"*\n",
    "ridit07/portfolio-ridit-jain": "",
    "ridit07/cryptography-in-qmt": "# QMT — Quantum Cryptography Playground (BB84, BBM92, TF-QKD)\n\nA hands-on repo based on our end-sem project: building a **quantum-safe messaging demo** that combines **QKD protocols** (BB84, BBM92, TF-QKD) with **classical crypto** (AES/RSA), plus a simple **React chat UI** and a **Flask/Firebase** backend. The goal: show end-to-end key generation, auth, and text/image encryption—without requiring the user to know quantum mechanics.\n\n---\n\n## 📝 Short Description\nWe simulate QKD to generate shared keys (detecting eavesdropping by design), then use those keys for symmetric encryption of **messages** and **images**. A React chatbot guides the flow; the backend runs **FastAPI/Flask + Qiskit** for the protocol logic and stores auth/metadata in **Firebase Firestore**.\n\n---\n\n## 🔍 What’s Inside\n\n- **Protocols implemented**\n  - **BB84** (prepare-and-measure) — text + image encryption workflow.\n  - **BBM92** (entanglement-based) — key exchange via correlated measurements.\n  - **TF-QKD** (twin-field) — long-distance-friendly variant with a middle measurement node; also used with auth + image encryption.\n- **Classical crypto**\n  - **AES/Fernet** for payload encryption; **RSA** and **digital signatures/SSL/TLS** for channel hardening & integrity.\n- **Apps**\n  - **Frontend**: React chatbot that walks the user through key-gen, encrypt/decrypt, and checks.\n  - **Backend**: FastAPI/Flask service that runs QKD circuits (Qiskit), derives keys, and talks to Firebase.\n\n---\n\n## 🧠 How It Works (High-Level)\n\n1. **Key setup**\n   - Pick random bases/angles (BB84/BBM92) or phases (TF-QKD); prepare qubits / weak coherent states.  \n   - Send/measure; keep only the **matching settings** to build a raw key; run **verification** to detect eavesdropping.\n2. **Key to cipher key**\n   - Hash/derive the shared bits (e.g., **SHA-256 → 32-byte** key) for **AES/Fernet**.\n3. **Encrypt data**\n   - **Text**: XOR/AES with the shared key; **Image**: grayscale/flatten → XOR or Base64 + AES; send over public channel.\n4. **Decrypt & verify**\n   - Receiver uses the same shared key to restore plaintext/image; optional signatures/SSL/TLS for integrity.\n\n**Why TF-QKD?** Extends feasible distance via interference at an untrusted middle node, improving practicality beyond basic BB84/BBM92 for longer links (with precise measurements).\n\n---\n\n## 🧪 Results (from the report)\n\n- End-to-end demos for **BB84/BBM92/TF-QKD** with working **text & image** encryption flows and security checks (basis/phase matching + discard).  \n- Simulations/circuits show **entanglement-based** keygen, **weak coherent state** interference, and full **auth → keygen → encrypt/decrypt** paths.\n\n> Figures referenced in the report: BB84/TF-QKD circuits, shared key derivation, image encryption examples, and chatbot UI snapshots.\n\n---\n\n## 🧰 Tech Stack\n\n- **Quantum**: Qiskit, AerSimulator.  \n- **Backend**: Python, Flask/FastAPI.  \n- **Frontend**: React.js.  \n- **DB**: Firebase Firestore.  \n- **Crypto**: AES/Fernet, RSA, TLS, signatures.\n\n\n---\n\n## ▶️ Usage (Demo Flow)\n\n1. **Register/Login** in the web UI  \n   Firestore stores the user profile and a quantum auth secret.\n\n2. **Pick a protocol**  \n   Choose **BB84**, **BBM92**, or **TF-QKD**.\n\n3. **Run key generation**  \n   The UI triggers the backend to simulate, reconcile, and verify the shared key.\n\n4. **Encrypt**\n   - **Text**: AES/Fernet encryption (client/server workflow).\n   - **Image**: Grayscale/flatten → XOR or Base64 + AES (TF-QKD demo).\n\n5. **Send/Receive**  \n   Encrypted messages/files are stored in Firestore; the receiver decrypts locally.\n\n---\n\n## 🔐 Security Notes\n\n- **Eavesdrop detection** is built in: high error rates or mismatched bases/phases → abort & restart.\n- **TF-QKD relay risks**: the middle node is untrusted; protocol still resists passive attacks but requires careful measurement integrity.\n- **Classical hardening**: use TLS, digital signatures, and proper key derivation to close implementation gaps.\n\n",
    "ridit07/combining-ml-and-dl-approaches-to-enhance-antimicrobial-peptide-discovery-and-effectiveness": "# Combining ML & DL to Enhance Antimicrobial Peptide (AMP) Discovery\n\nA research repo for our paper on fusing machine learning (ML) and deep learning (DL) to predict, design, and validate antimicrobial peptides. We combine sequence-level models (SVM, Random Forest, XGBoost, Logistic Regression, RNN) with image/structure models (custom CNN, VGG16, ResNet50, InceptionV3), and use XAI (SHAP/LIME) to interpret what actually drives predictions. The work targets the AMR (antimicrobial resistance) problem and closes the gap between in-silico ranking and lab validation concepts like SAXS/killing assays.\n\n---\n\n## Short description\n\nAntimicrobial peptides are promising antibiotic alternatives—but finding effective ones is hard. We integrate sequence features and structural signals, evaluate a spectrum of ML/DL models, and interpret them with SHAP/LIME to surface the physicochemical patterns that matter (e.g., molecular weight, length, hydrophobicity). The goal: a practical, reproducible path to identify and refine high-value AMP candidates.\n\n---\n\n## Highlights\n\n- **Problem**: Existing AMP discovery often treats sequence and structure separately, missing cross-modal dependencies that drive real efficacy.  \n- **Approach**: Dual track—tabular/sequence ML + structural/image DL—with careful preprocessing, model selection, and hyperparameter tuning.  \n- **Interpretability**: SHAP (global) + LIME (local) to explain feature influence and single-prediction rationale; used to sanity-check “what the model learned”.  \n- **Outcome**: Consistent strong results on sequence ML (RF/XGB/SVM/LogReg) and best-in-class accuracy from ResNet50 on image tasks; model trade-offs documented via PR/ROC curves.\n\n---\n\n## Data sources (as used/reviewed)\n\n- AMP sequence databases: **CAMP**, **DBAASP**, **DRAMP**, **YADAMP**; negatives from **UniProt**.  \n- Structures/imagery: **RCSB PDB** (for structural views/derivatives).\n\n> The paper also surveys three cornerstone studies: SVM + Pareto frontier for membrane activity, dual-LSTM generation/classification for novel AMPs, and **AMPlify** (BiLSTM + attention) for WHO-priority pathogens. We align our pipeline with those directions.\n\n---\n\n## Methods (what we actually ran)\n\n### Sequence / tabular models\n- **Random Forest**, **XGBoost**, **Logistic Regression**, **SVM**, **RNN**.  \n- Preprocessing: cleaning, type coercion, feature engineering (MW, length, charge, hydrophobicity indices, aromaticity, isoelectric point), class balance checks.  \n- Tuning: `GridSearchCV` (n_estimators, depth, min_samples_* for RF; C/γ/kernel for SVM, etc.).  \n- **Explainability**: SHAP summary & dependence plots; LIME per-sample attributions.\n\n### Image / structure models\n- **Custom CNN** baseline.  \n- **Transfer learning**: VGG16, ResNet50, InceptionV3 (frozen → unfrozen heads, small data regimes, regularization).  \n- Training diagnostics: train/val curves, precision–recall analysis for threshold choice.\n\n---\n\n## Results (as reported in the paper)\n\n### Sequence models (structural bioinformatics classification)\n- **Random Forest**: **Accuracy 98.39%**, **ROC AUC 99.79%**  \n- **XGBoost**: **Accuracy 98.36%**, **ROC AUC 99.80%**  \n- **Logistic Regression**: Accuracy 97.47%, ROC AUC 99.27%  \n- **SVM**: Accuracy 98.10%, ROC AUC 99.67%  \n- Additional study variant: XGBoost **ROC AUC ≈ 0.92** under a different sequential setup (dataset/task change noted in paper).\n\n### Image models\n- **Custom CNN**: ~**87%** accuracy  \n- **VGG16**: ~**90%** accuracy  \n- **InceptionV3**: ~**91%** accuracy  \n- **ResNet50**: **~92%** accuracy (best overall for image classification in our setting)  \n- PR curves show ResNet50’s precision strength across recall ranges; RNN favored when high recall is critical on sequence tasks.\n\n### What mattered (XAI)\n- SHAP ranked **Molecular Weight** and **Length** as top influences; hydrophobicity (GRAVY), aromaticity, and isoelectric point showed nuanced, sometimes nonlinear effects.  \n- LIME clarified per-sample decisions (pro/con feature bars with predicted probabilities). These checks reduced the risk of spurious correlations.\n",
    "ridit07/ipl-prediction-app": "# IPLitics — IPL Insights & Predictions\n\nA student-built app that mixes live IPL info with simple ML models so fans can explore player/team stats and try basic score/outcome predictions. Built with Flutter + Python (Flask), designed in Figma, and backed by a small analytics pipeline.\n\n---\n\n## 🎯 Objective\nWe wanted a clean, reliable place for IPL fans to check form, compare players/teams, and play with data-driven predictions — not just a fantasy lineup tool or a score ticker.  \nThe aim was to combine real-time match info with historical data analysis and basic machine learning for quick insights.\n\n---\n\n## 📌 Features\n\n- **Live Match View** — Displays scores and key stats in a familiar scoreboard style.\n- **Top Players & Teams** — Carousels leading to detailed views with stats like matches played, runs, strike rate, wickets, coach, and roster.\n- **Quick Selections** — Dropdowns and pickers for faster, cleaner data input.\n- **Basic Predictions** — Simple models estimating batting and bowling outcomes based on recent stats.\n\n---\n\n## 📱 Screens\n\n- **Home** — Carousels for quick navigation.\n- **Live Matches**\n- **Players**\n- **Teams**\n\n---\n\n## 🛠 Tech Stack\n\n### **Design**\n- Figma — Low-fidelity → high-fidelity flows\n\n### **Mobile App**\n- Flutter (Dart) — `carousel_pro`, `url_launcher`, `Cupertino`, `BottomNavigationBar`, `ListView.builder`, async/await\n- AnimationController for smooth UI transitions\n- `HttpOverrides` for live API integration\n\n### **Backend**\n- Python + Flask REST API\n\n### **Machine Learning**\n- EDA → PCA / feature filtering → Model training → Deployment\n- Simple models for explainability and speed\n\n---\n\n## 📊 Data & Modeling\n\n### **EDA Highlights**\n- Cleaned batting & bowling data\n- Fixed null/missing values and unified data types\n- Derived opponent team per innings for better context\n\n### **Feature Screening**\n- Checked correlations (e.g., Runs ↔ Balls Faced ≈ 0.93)\n- Removed highly correlated or irrelevant features\n\n### **Model Results**\n#### Batsman (Demographic Features)\n- KNN: **0.9729**\n- Linear Regression: **0.9806**\n- Random Forest: **0.9757**\n\n#### Bowler (Demographic Features)\n- KNN: **0.2242**\n- Linear Regression: **0.3507**\n- Random Forest: **0.3640**\n\n> Overall app outcomes: **~93% accuracy** across test matches.\n\n---\n",
    "ridit07/image-based-emotion-age-gender-recognition-and-song-recommendation-system": "# 🎵 Emotion, Age & Gender-Based Music Recommendation System\n\n## 📌 Overview\nThis AI-powered system captures a user's facial image through a webcam, detects **emotion**, **age**, and **gender**, and recommends a personalized music playlist accordingly.  \nIt aims to provide an engaging and context-aware listening experience by blending **computer vision**, **machine learning**, and **music recommendation** techniques.\n\n## 🖼 Demo\n![Demo Image](Demo_Image.png)\n\n## ⚙ How It Works\n1. **Capture Face** – OpenCV captures a frame from the webcam.\n2. **Face Detection & Analysis** – Pre-trained models detect facial landmarks, estimate **age**, **gender**, and classify **emotion** (e.g., happy, sad, angry, neutral).\n3. **Music Recommendation** – Based on detected attributes, the system fetches a curated playlist from a music database.\n4. **Output Display** – Shows detected attributes and the recommended playlist in real-time.\n\n## 🛠 Tech Stack\n- **Python** – Core programming language\n- **OpenCV** – Webcam access & face detection\n- **DeepFace / FER** – Emotion, age, gender prediction\n- **Pandas** – Music database handling\n- **Streamlit / Tkinter** – User interface\n- **Scikit-learn** – Additional ML support\n\n## 📊 Example Output\n- Detected Emotion: happy\n- Predicted Age: 18\n- Predicted Gender: Male\n  \n- Suggested Music:\n\n1. On My Way – Robbie Rivera (Happy)\n2. The Joker – Steve Miller Band (Happy)\n3. Dance Little Sister – Terence Trent D’Arby (Happy)\n4. Mad About You – Hooverphonic (Happy)\n4. Wonderful Together – Blasterjaxx (Happy)\n\n   \n## 📈 Evaluation Metrics\nWe evaluated the system using a labeled test dataset containing emotion, age, and gender ground truth values.\n\n| Metric                | Emotion Detection | Age Prediction | Gender Prediction |\n|-----------------------|-------------------|----------------|-------------------|\n| Accuracy              | 92%               | 85%            | 97%               |\n| Precision             | 91%               | 84%            | 96%               |\n| Recall                | 90%               | 83%            | 97%               |\n| F1-Score              | 90.5%             | 83.5%          | 96.5%             |\n\n> **Note:** Metrics may vary based on lighting, camera quality, and dataset diversity.\n\n## 🔍 Comparison Analysis\n| Technique                                                      | Accuracy  |\n|----------------------------------------------------------------|-----------|\n| Prediction of emotion using pre-processing                     | 66.4%     |\n| Prediction of emotion using Gaussian blur and equalized histogram | 74.4%  |\n| Prediction of emotion using filter and CNN model               | 80.6%     |\n| Prediction of age and gender                                   | 84% and 94% |\n| Prediction of song suggestion based on emotion                 | 94.6%     |\n\n> **Insight:** Advanced filtering and CNN models significantly improve emotion detection accuracy.  \n> Song recommendation based on detected emotion achieves the highest accuracy.\n\n",
    "ridit07/research-chatgpt-can-change-the-world": "# 🌍 AI & ChatGPT: How Generative AI Can Change the World\n\nThis repository contains a research study exploring the **transformative impact of ChatGPT and similar generative AI models** on society, industry, and daily life.  \nIt examines opportunities, challenges, and ethical implications of deploying conversational AI at scale.\n\n---\n\n## 📜 Abstract\n\nChatGPT, a large language model trained by OpenAI, has demonstrated remarkable ability in natural language understanding and generation.  \nThis research discusses how such models can:\n\n- Revolutionize **education**, **healthcare**, and **customer service**\n- Automate repetitive workflows and improve productivity\n- Democratize access to information and expertise\n- Raise critical **ethical**, **legal**, and **societal** questions\n\n---\n\n## 📚 Key Research Areas\n\n- **Technology Overview**\n  - Foundation models, fine-tuning, reinforcement learning from human feedback (RLHF)\n  - Scaling laws and architecture basics\n\n- **Potential Applications**\n  - Education & tutoring  \n  - Healthcare diagnostics & patient interaction  \n  - Legal assistance  \n  - Creative industries (writing, design, media)\n\n- **Economic Impact**\n  - Automation & job displacement vs. job creation\n  - Productivity gains and new business models\n\n- **Ethical & Societal Challenges**\n  - Bias and fairness\n  - Misinformation risks\n  - Privacy and data governance\n  - Regulation & policy considerations\n\n---\n\n## 🧠 Conclusions\n\n- Generative AI like ChatGPT can significantly improve efficiency and innovation.\n- Its benefits depend on **responsible deployment** and continuous oversight.\n- Policymakers, technologists, and the public must collaborate to ensure **ethical alignment**.\n\n---\n\n## 📄 Repository Contents\n\nThis repo contains:\n\n- **Full Research Report (PDF)** – detailing findings, examples, and references.\n- **No executable code** – this is purely an academic/research resource.\n\n---\n",
    "ridit07/universal-turing-machine-simulator": "# Universal Turing Machine Simulator\n\nThis project simulates a Universal Turing Machine (UTM) that can take another Turing Machine (TM) and an input string `w`, and mimic the behavior of the TM. The UTM will accept or reject the string `w` based on the behavior of the TM.\n\n## Features\n\n- Simulates the behavior of any given Turing Machine\n- Accepts or rejects input strings based on the given Turing Machine's rules\n- Implements Object-Oriented Programming (OOP) concepts\n\n## Components\n\n### Turing Machine (TM)\n- States\n- Alphabet\n- Transition Function\n- Initial State\n- Blank Symbol\n- Final States\n\n### Universal Turing Machine (UTM)\n- Input Turing Machine's definition\n- Input string `w`\n- Simulation of the Turing Machine's behavior\n\n## Example\n\nAn example Turing Machine is provided and tested within the program to validate the results.\n\n## Diagrams\n\nClear diagrams showing the working of the UTM and its representation are included in the project.\n\n## Data Structures\n\nDetailed explanation of the data structures used to solve the problem is provided in the report.\n\n## Usage\n\nTo run the simulation, execute the main program file. Ensure you have the necessary dependencies installed.\n\n## Submission\n\nThe project includes:\n- Program code\n- Example run and screenshots of the output\n- Detailed report in the provided template\n\n## Report\n\nThe report includes:\n- Clear diagrams of UTM working and representation\n- Detailed explanation of data structures\n- Program code and screenshots of output\n\n\n\n",
    "ridit07/hcl-internship-demo-recruitment-invoice-tool": "# 📄 Recruitment Invoice Tool (HCL Internship)\n\nA production-grade workflow tool built during my **HCL Technologies** internship to streamline the **vendor claim → verification → rate card → invoice** pipeline.  \nIt replaces error-prone manual handling with an auditable, role-based system spanning Vendors, Source Validation, HR, and Finance—plus an **AI-assisted rate-card generator** from CV content.\n\n> Timeline: Jun 1, 2023 – Aug 2, 2023 · Practice School II (PS-II) · BML Munjal University\n\n---\n\n## ✨ Key Capabilities\n\n- **Vendor Claim Submission**\n  - Guided form to raise new claims (candidate details, role, location, experience, skill tags, CV upload)\n  - Automatic claim ID and time-stamped audit trail\n  - Real-time **claim status** tracking\n\n- **Verification Workflow**\n  - **Source Validation Team**: authenticity checks (data cross-verify, refer-back with mandatory remarks, approve/reject)\n  - **HR Team**: skill/role sanity (vanilla, Cloud, AI/ML, seniority & fit), approve/reject with notes\n\n- **AI-Assisted Rate Card Generation**\n  - **CV content extraction** → region, experience, skills, seniority, criticality\n  - Model proposes **preliminary rate card** using configurable rules\n  - Finance can **override/edit** before finalizing\n\n- **Finance & Invoicing**\n  - Rate card approval → invoice line-items auto-computed\n  - Tax & totals calculation, versioned approvals, payment readiness flag\n  - Complete action log for audit & dispute resolution\n\n- **Access & Experience**\n  - Secure login, forgot-password flow\n  - Role-based UI (Vendor / Source Validation / HR / Finance / Admin)\n  - Responsive, HCL-branded UX (Figma → Flutter)\n\n---\n\n## 🧭 Workflow (High-Level)\n\n1. **Vendor** submits claim + CV  \n2. **Source Validation** checks authenticity → _Approve / Refer-Back (mandatory remark) / Reject_  \n3. **HR** validates role/skills/experience → _Approve / Reject_  \n4. **Finance**:\n   - AI parses CV → proposes **rate card** (region, exp, skills, importance)\n   - Finance reviews → edits if needed → **finalizes**\n5. **Invoice** auto-prepared per approved rate card  \n6. **Vendor & internal teams** can view real-time status with full audit trail\n\n---\n\n## 🏗️ Architecture (Conceptual)\n\n- **Frontend**: **Flutter (Dart)** SPA  \n- **Backend API**: **Python** (Flask/FastAPI)  \n- **Database**: **SQL** (normalized schema for claims, users/roles, approvals, rate cards, invoices, remarks)  \n- **Middleware/APIs**: for auth, file storage, verification steps, AI model invocation  \n- **AI Component**: CV parsing → signal extraction → preliminary **rate-card** suggestion  \n- **Deployment**: HCL’s test/prod servers with standard security hardening\n\n---\n\n## 🛠 Tech Stack\n\n- **UI/UX**: Figma → Flutter\n- **Backend**: Python (Flask/FastAPI), JWT-based auth\n- **DB**: MySQL / PostgreSQL\n- **AI/NLP**: CV content extraction + rule/model-driven rate-card suggestion\n- **Docs & Diagrams**: DFDs, ER diagram (claims, approvals, roles, rate cards, invoices)\n\n---\n\n## 🔐 Roles & Permissions\n\n- **Vendor**: create claims, upload CV, track status, respond to refer-backs  \n- **Source Validation**: verify authenticity, approve/reject, refer-back with remarks  \n- **HR**: validate skills/role/experience, approve/reject  \n- **Finance**: generate/override **rate cards**, finalize for invoicing  \n- **Admin**: user/role management, configuration (regions, tax rules, skill catalogs)\n\n---\n\n\n## ✅ Outcomes\n\n- Reduced manual handling & errors in vendor claims  \n- Faster turnaround with **AI-assisted** rate cards  \n- Clear audit trail & refer-back rationale  \n- Better vendor transparency & internal accountability  \n- Production-ready deployment practices (staged rollouts, security, config mgmt)\n\n",
    "ridit07/nurturing-positivity-enhancing-news-summarization-through-reinforcement-learning-llm": "# 📰 Nurturing Positivity: Enhancing News Summarization through Reinforcement Learning\n\n> A novel approach to news summarization that promotes positive and constructive narratives by integrating sentiment and toxicity control into the summarization process.\n\n---\n\n## 📌 Overview\n\nThis project tackles the challenge of bias and negativity in automated news summarization.  \nWhile large language models can generate concise summaries, they often amplify sensational or negative content.  \nOur goal was to develop a summarization system that **preserves factual accuracy while promoting positivity**, using **Reinforcement Learning (RL)** with sentiment and toxicity feedback.\n\nWe fine-tuned a **FLAN-T5** model with **Proximal Policy Optimization (PPO)**, guided by **RoBERTa-based sentiment and toxicity detectors**, to produce summaries that are both informative and uplifting.\n\n---\n\n## 🎯 Objectives\n\n- Generate accurate, concise summaries of news articles.\n- Minimize harmful, toxic, or excessively negative content.\n- Encourage positive framing without distorting facts.\n- Explore RL-based fine-tuning for controlled text generation.\n\n---\n\n## 🛠 Methodology\n\n1. **Base Model Selection**  \n   - Used **FLAN-T5** (Google’s instruction-tuned T5 model) for summarization.\n   \n2. **Dataset**  \n   - **CNN/DailyMail** dataset for initial supervised summarization.\n   - Custom sentiment and toxicity scoring models for RL feedback.\n\n3. **Reward Models**  \n   - **Sentiment Model**: RoBERTa fine-tuned for sentiment classification.\n   - **Toxicity Model**: RoBERTa fine-tuned for toxicity/hate-speech detection.\n\n4. **Training Pipeline**  \n   - Stage 1: Supervised fine-tuning on summarization.\n   - Stage 2: PPO-based RL fine-tuning with sentiment/toxicity rewards.\n   - Balanced multi-objective reward function:  \n     `Reward = α * SentimentScore - β * ToxicityScore`\n\n5. **Evaluation**  \n   - **ROUGE-1/2/L** for content fidelity.\n   - **Sentiment shift** and **toxicity reduction** metrics.\n   - Human evaluation for qualitative feedback.\n\n---\n\n## 📊 Results\n\n| Model               | ROUGE-L | Positivity ↑ | Toxicity ↓ |\n|---------------------|---------|--------------|------------|\n| Baseline FLAN-T5    | 0.281   | 52%          | 14%        |\n| RL-tuned FLAN-T5    | 0.276   | **71%**      | **5%**     |\n\n- RL tuning maintained summary quality while **increasing positive sentiment** by ~19% and **reducing toxicity** by ~9%.\n- Human evaluators preferred RL-tuned summaries for tone and engagement.\n\n---\n\n## 🚀 Tech Stack\n\n- **Language Model**: FLAN-T5\n- **RL Algorithm**: Proximal Policy Optimization (PPO)\n- **Reward Models**: RoBERTa (sentiment & toxicity)\n- **Frameworks**: PyTorch, Hugging Face Transformers, trl (HF RL library)\n\n---\n\n",
    "ridit07/e-commerce-purchase-prediction-ml": "# 🛒 E-Commerce Purchase Prediction\n\n> Predict whether a customer will make a purchase on an e-commerce website using Machine Learning models, with 89% accuracy achieved via Random Forest.\n\n---\n\n## 📌 Overview\n\nWith the shift from physical stores to online shopping, understanding customer behaviour has become critical for improving conversions.  \nThis project builds and compares multiple ML models to predict purchase intent using clickstream and customer session data.  \n\nBy focusing on the most relevant features from user browsing behaviour, the model achieves high accuracy without relying on personal information — addressing privacy concerns while maintaining performance.\n\n---\n\n## 🎯 Objectives\n\n- Classify website visitors as **Buy** or **Not Buy**.\n- Compare the performance of multiple ML models on the same dataset.\n- Identify which features and algorithms yield the best predictive accuracy.\n- Deploy the best model in a **Streamlit web app** for real-time prediction.\n\n---\n\n## 📊 Dataset\n\n- **Source:** [UCI Machine Learning Repository – Online Shoppers Purchasing Intention Dataset](https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset)\n- **Instances:** 12,330 sessions (each session belongs to a unique user over a year)\n- **Attributes:** 18 total (10 numerical, 8 categorical)\n- **Target Variable:** `Revenue` (1 if purchase made, 0 otherwise)\n- **No missing values**\n\nKey Features include:\n- `PageValues` – Average value of a page viewed before a transaction\n- `ExitRates` – % of users who exit after visiting a specific page\n- `ProductRelated` & `ProductRelated_Duration` – Number and time spent on product pages\n- `BounceRates`, `Informational`, `Month`, `VisitorType`, `Weekend`, etc.\n\n---\n\n## 🛠 Methodology\n\n1. **Exploratory Data Analysis (EDA)** – Check distributions, detect outliers, understand feature relationships.\n2. **Data Preprocessing**\n   - Convert categorical to numeric\n   - Replace irrelevant values (e.g., `'Other'` → `'Returning_Visitor'`)\n   - Drop non-numeric columns (`Month`)\n3. **Feature Selection**\n   - Used `ExtraTreesClassifier` to rank feature importance\n   - Selected top 4 features: `PageValues`, `ExitRates`, `ProductRelated_Duration`, `ProductRelated`\n4. **Feature Scaling** – Standardized selected features.\n5. **Model Building**\n   - Logistic Regression\n   - K-Nearest Neighbors (KNN)\n   - Naïve Bayes\n   - Decision Tree\n   - Random Forest\n6. **Model Evaluation**\n   - Metrics: Accuracy, Classification Report\n   - Best Model: **Random Forest** (Accuracy: 89.2% after tuning)\n7. **Hyperparameter Tuning**\n   - Used GridSearchCV to optimize `max_depth`, `min_samples_leaf`, `min_samples_split`, `n_estimators`\n8. **Deployment**\n   - Streamlit app with sliders for inputting feature values\n   - Real-time predictions using the trained model\n\n---\n\n## 📈 Results\n\n| Model                   | Accuracy   |\n|-------------------------|------------|\n| Logistic Regression     | 86.9%      |\n| Decision Tree           | 85.1%      |\n| Random Forest           | **89.2%**  |\n| KNN                     | 87.6%      |\n| Naïve Bayes             | 86.6%      |\n\n- Random Forest provided the **highest accuracy and robustness**.\n- Only session-based behavioural data was needed for strong predictions.\n\n---\n\n## 🚀 Deployment\n\n**Streamlit App:** [Click to View](https://ridit07-ml-project-app-f3zc6r.streamlit.app/)  \n**GitHub Code:** [Repository Link](https://github.com/Ridit07/ml-project)\n\n---\n\n## 📂 Project Structure\n\n- 📦 e-commerce-purchase-prediction\n- ┣ 📜 app.py # Streamlit app for predictions\n- ┣ 📜 project.pkl # Trained Random Forest model\n- ┣ 📜 ML_Notebook.ipynb # Full EDA + model building notebook\n- ┣ 📜 requirements.txt # Python dependencies\n- ┗ 📜 README.md # Project documentation\n\n\n---\n\n## ⚙️ Installation & Usage\n\n### 1️⃣ Clone the Repository\n```bash\ngit clone https://github.com/Ridit07/ml-project.git\ncd ml-project\n```\n\n2️⃣ Install Dependencies\n```bash\npip install -r requirements.txt\n```\n\n3️⃣ Run the Streamlit App\n```bash\nstreamlit run app.py\n```\n\n## 📌 How to Use the App\n\n1. Use sliders to input:\n   - `PageValues`\n   - `ExitRates`\n   - `ProductRelated_Duration`\n   - `ProductRelated`\n2. Click **Predict**\n3. The app will output whether the customer is **likely to purchase**.\n\n---\n\n## 🧠 Key Insights\n\n- Session clickstream data is **more predictive** than static customer data.\n- `PageValues` was the **most important feature** for prediction.\n- Combining behavioural features yields better accuracy **without breaching privacy**.\n",
    "ridit07/web-browser": "",
    "ridit07/nlp-powered-legal-document-generation-system": "",
    "ridit07/classifying-sentiment-of-restaurant-reviews-nlp": "",
    "ridit07/infinity-graphics-node": "",
    "ridit07/library-management-app": ""
  }
}